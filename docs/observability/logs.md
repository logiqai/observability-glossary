# Logs

Logs are system-generated data files that contain immutable, time-stamped information about the events, operations, and usage data about that system. Logs can either be plaintext, structured, or binary in nature. 


Logs are widely considered to be one of the three pillars of observability. The analysis of log data is a process of simplifying the information logs contain and making better sense of it. The analysis of log data at a very granular level can give you innumerable insights into rare or infrequent anomalies in your system and uncover unforeseeable or erratic behavior among system components. 

There's a lot you can gain from properly analysing log data. The right log analysis and management tool can help you derive actionable insights for business, infrastructure, and security improvements, identify usage patterns, detect threats and anomalies as they begin to manifest, identify root causes of issues, and help in the remediation of threats and issues. 

Log data can also be abstracted to the two remaining pillars of observability - traces and metrics. 

## Also read

- [8 Logging Best Practices You Should Already Know](https://logiq.ai/8-logging-best-practices-you-should-already-know/)
- [Log Management on LOGIQ vs ELK Stack](https://logiq.ai/log-management-on-logiq-vs-elk-stack/)
- [Log aggregation design considerations](https://logiq.ai/log-aggregation-design-considerations/)
- [Log2Metrics â€“ Convert logs to a real-time metric](https://logiq.ai/log2metrics-convert-logs-to-a-real-time-metric/)